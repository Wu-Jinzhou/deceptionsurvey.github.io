<!DOCTYPE html>
<html class="fontawesome-i2svg-active fontawesome-i2svg-complete">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<meta name="description" content="Top 10 AI Deception Papers">
	<meta name="keywords" content="AI Deception, Top Papers, Research, Machine Learning">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Top-10 Papers - AI Deception Survey</title>
	<link rel="icon" href="./assets/logo_transp.png" type="image/png">
	<!-- 引入css文件 -->
	<link href="./assets/css" rel="stylesheet">
	<link rel="stylesheet" href="./assets/bulma.min.css">
	<link rel="stylesheet" href="./assets/bulma-carousel.min.css">
	<link rel="stylesheet" href="./assets/font-face.css">
	<link rel="stylesheet" href="./assets/bulma-slider.min.css">
	<link rel="stylesheet" href="./assets/fontawesome.all.min.css">
	<link rel="stylesheet" href="./assets/academicons.min.css">
	<link rel="stylesheet" href="./assets/index.css">
	<link rel="stylesheet" href="./assets/leaderboard.css">
	<style>
		p, ul {
		text-align: justify;
		margin-left: auto;
		margin-right: auto;
		width: 75%;
		list-style:disc;
		margin-bottom: 10px;
		}
		li {
		margin-bottom: 10px;
		}
		
		.section-card {
		background-color: #f8f9fa;
		border: 1px solid #e1e5e9;
		border-radius: 12px;
		padding: 25px;
		margin: 25px 0;
		box-shadow: 0 4px 8px rgba(0,0,0,0.1);
		transition: transform 0.3s ease, box-shadow 0.3s ease;
		}
		
		.section-card:hover {
		transform: translateY(-5px);
		box-shadow: 0 8px 16px rgba(0,0,0,0.15);
		}
		
		.section-card h3 {
		color: #2c3e50;
		margin-bottom: 15px;
		}
		
		.section-card h2 {
		color: #2c3e50;
		margin-bottom: 20px;
		font-size: 2.5em;
		font-weight: bold;
		text-align: center;
		}
		
		.paper-card {
		background: white;
		border: 2px solid #e1e5e9;
		border-radius: 15px;
		padding: 30px;
		margin: 25px 0;
		transition: all 0.3s ease;
		position: relative;
		overflow: hidden;
		}
		
		.paper-card:hover {
		border-color: #DC143C;
		transform: translateY(-5px);
		box-shadow: 0 12px 24px rgba(220, 20, 60, 0.2);
		}
		
		.paper-rank {
		position: absolute;
		top: -10px;
		left: -10px;
		width: 60px;
		height: 60px;
		background: linear-gradient(45deg, #B22222, #DC143C);
		color: white;
		border-radius: 50%;
		display: flex;
		align-items: center;
		justify-content: center;
		font-size: 1.5em;
		font-weight: bold;
		box-shadow: 0 4px 8px rgba(0,0,0,0.3);
		}
		
		.paper-title {
		color: #2c3e50;
		font-size: 1.4em;
		font-weight: bold;
		margin-bottom: 10px;
		margin-left: 40px;
		font-family: 'Times New Roman', 'Times', serif;
		}
		
		.paper-authors {
		color: #6c757d;
		font-style: italic;
		margin-bottom: 10px;
		margin-left: 40px;
		}
		
		.paper-venue {
		display: inline-block;
		background: linear-gradient(45deg, #B22222, #DC143C);
		color: white;
		padding: 5px 15px;
		border-radius: 20px;
		font-size: 0.9em;
		font-weight: bold;
		margin-bottom: 15px;
		margin-left: 40px;
		}
		
		.paper-abstract {
		margin-left: 40px;
		color: #495057;
		line-height: 1.6;
		margin-bottom: 20px;
		}
		
		.paper-links {
		margin-left: 40px;
		}
		
		.paper-link {
		display: inline-block;
		background-color: #f8f9fa;
		border: 2px solid #DC143C;
		color: #DC143C;
		padding: 8px 16px;
		border-radius: 8px;
		text-decoration: none;
		margin-right: 10px;
		margin-bottom: 10px;
		transition: all 0.3s ease;
		font-weight: 500;
		}
		
		.paper-link:hover {
		background-color: #DC143C;
		color: white;
		transform: scale(1.05);
		}
		
		.impact-score {
		position: absolute;
		top: 20px;
		right: 20px;
		background: rgba(220, 20, 60, 0.1);
		border: 2px solid #DC143C;
		color: #DC143C;
		padding: 10px 15px;
		border-radius: 10px;
		font-weight: bold;
		}
		
		.methodology-tag {
		display: inline-block;
		background-color: #e9ecef;
		color: #495057;
		padding: 4px 12px;
		border-radius: 15px;
		font-size: 0.85em;
		margin-right: 8px;
		margin-bottom: 8px;
		}
		
		.filter-buttons {
		text-align: center;
		margin: 30px 0;
		}
		
		.filter-btn {
		background: linear-gradient(45deg, #B22222, #DC143C);
		color: white;
		border: none;
		padding: 10px 20px;
		border-radius: 25px;
		margin: 0 10px;
		cursor: pointer;
		transition: all 0.3s ease;
		font-weight: 500;
		}
		
		.filter-btn:hover, .filter-btn.active {
		transform: scale(1.1);
		box-shadow: 0 4px 8px rgba(220, 20, 60, 0.3);
		}
	</style>
</head>

<nav class="navbar is-light" role="navigation" aria-label="main navigation" style="padding: 0; box-shadow: 0 4px 12px rgba(0,0,0,0.15); background: linear-gradient(to bottom, #ffffff 0%, #f8f9fa 100%); border-bottom: 1px solid #e9ecef;">
	<div class="container" style="max-width: 1200px; margin: 0 auto; padding: 0 40px;">
		<div class="navbar-brand">
			<a class="navbar-item" href="index.html" style="font-weight: bold; font-size: 1.3em; color: #000000; font-family: 'Times New Roman', 'Times', serif; margin-left: 20px;">
				AI Deception
			</a>
			<a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false" data-target="navbarBasicExample">
				<span aria-hidden="true"></span>
				<span aria-hidden="true"></span>
				<span aria-hidden="true"></span>
			</a>
		</div>

		<div id="navbarBasicExample" class="navbar-menu">
			<div class="navbar-start" style="margin-left: 60px;">
				<a class="navbar-item" href="overview.html" style="font-weight: 500; color: #000000; font-family: 'Times New Roman', 'Times', serif; transition: all 0.3s ease; position: relative;" onmouseover="this.style.color='#DC143C'; this.style.transform='translateY(-2px)'" onmouseout="this.style.color='#000000'; this.style.transform='translateY(0)'">
					Overview
				</a>
				
				<a class="navbar-item" href="top10papers.html" style="font-weight: 500; color: #000000; font-family: 'Times New Roman', 'Times', serif; transition: all 0.3s ease; position: relative; background-color: rgba(220, 20, 60, 0.1);" onmouseover="this.style.color='#DC143C'; this.style.transform='translateY(-2px)'" onmouseout="this.style.color='#000000'; this.style.transform='translateY(0)'">
					Top-10 Papers
				</a>
				
				<a class="navbar-item" href="tutorials.html" style="font-weight: 500; color: #000000; font-family: 'Times New Roman', 'Times', serif; transition: all 0.3s ease; position: relative;" onmouseover="this.style.color='#DC143C'; this.style.transform='translateY(-2px)'" onmouseout="this.style.color='#000000'; this.style.transform='translateY(0)'">
					Tutorials
				</a>
				
				<div class="navbar-item has-dropdown is-hoverable">
					<a class="navbar-link" style="font-weight: 500; color: #000000; font-family: 'Times New Roman', 'Times', serif; transition: all 0.3s ease;" onmouseover="this.style.color='#DC143C'" onmouseout="this.style.color='#000000'">
						More Research
					</a>
					<div class="navbar-dropdown" style="box-shadow: 0 8px 16px rgba(0,0,0,0.1); border: 1px solid #e9ecef;">
						<a class="navbar-item" href="https://pku-lm-resist-alignment.github.io/" target="_blank" style="font-family: 'Times New Roman', 'Times', serif;">
							<b>Resist (ACL2025 <span style="color: #DC143C; font-weight: bold;">Best Paper</span>)</b>
						</a>
						<a class="navbar-item" href="https://github.com/PKU-Alignment/safe-rlhf" target="_blank" style="font-family: 'Times New Roman', 'Times', serif;">
							<b>SafeRLHF (ICLR 2024 Spotlight)</b>
						</a>
						<a class="navbar-item" href="https://huggingface.co/datasets/PKU-Alignment/PKU-SafeRLHF" target="_blank" style="font-family: 'Times New Roman', 'Times', serif;">
							<b>PKU-SafeRLHF (ACL2025 Main)</b>
						</a>
						<a class="navbar-item" href="https://github.com/PKU-Alignment/aligner" target="_blank" style="font-family: 'Times New Roman', 'Times', serif;">
							<b>Aligner (NeurIPS 2024 Oral)</b>
						</a>
						<a class="navbar-item" href="https://github.com/PKU-Alignment/safe-sora" target="_blank" style="font-family: 'Times New Roman', 'Times', serif;">
							<b>SafeSora (NeurIPS 2024 DB Track)</b>
						</a>
						<a class="navbar-item" href="https://github.com/PKU-Alignment/beavertails" target="_blank" style="font-family: 'Times New Roman', 'Times', serif;">
							<b>BeaverTails (NeurIPS 2023 DB Track)</b>
						</a>
						<a class="navbar-item" href="https://align-anything.readthedocs.io/en/latest/index.html" target="_blank" style="font-family: 'Times New Roman', 'Times', serif;">
							<b>Align-Anything🔥🔥🔥</b>
						</a>
						<a class="navbar-item" href="https://alignmentsurvey.com" target="_blank" style="font-family: 'Times New Roman', 'Times', serif;">
							<b>AI Alignment: A Comprehensive Survey</b>
						</a>
					</div>
				</div>
			</div>

			<div class="navbar-end">
				<div class="navbar-item">
					<div class="field has-addons">
						<div class="control">
							<input class="input" type="text" id="searchInput" placeholder="Search papers, topics..." style="width: 280px; font-family: 'Times New Roman', 'Times', serif; border: 2px solid #e9ecef; border-radius: 8px 0 0 8px; box-shadow: inset 0 2px 4px rgba(0,0,0,0.1);">
						</div>
						<div class="control">
							<button class="button" onclick="performSearch()" style="background: linear-gradient(45deg, #B22222, #DC143C); color: white; border: none; border-radius: 0 8px 8px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1); transition: all 0.3s ease;" onmouseover="this.style.transform='scale(1.05)'" onmouseout="this.style.transform='scale(1)'">
								<span class="icon">
									<svg width="16" height="16" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
										<path d="M21 21L16.514 16.506L21 21ZM19 10.5C19 15.194 15.194 19 10.5 19C5.806 19 2 15.194 2 10.5C2 5.806 5.806 2 10.5 2C15.194 2 19 5.806 19 10.5Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
									</svg>
								</span>
							</button>
						</div>
					</div>
				</div>
			</div>
		</div>
	</div>
</nav>

<script>
function performSearch() {
	const searchTerm = document.getElementById('searchInput').value.toLowerCase();
	if (searchTerm.trim() === '') {
		alert('请输入搜索内容');
		return;
	}
	
	// 搜索页面内容
	const sections = document.querySelectorAll('.paper-card, .section-card, .content p, h1, h2, h3');
	let found = false;
	
	sections.forEach(section => {
		const text = section.textContent.toLowerCase();
		if (text.includes(searchTerm)) {
			section.scrollIntoView({ behavior: 'smooth', block: 'center' });
			section.style.backgroundColor = '#ffeb3b';
			setTimeout(() => {
				section.style.backgroundColor = '';
			}, 3000);
			found = true;
			return;
		}
	});
	
	if (!found) {
		alert(`未找到相关内容: "${searchTerm}"`);
	}
}

// 回车键搜索
document.getElementById('searchInput').addEventListener('keypress', function(e) {
	if (e.key === 'Enter') {
		performSearch();
	}
});

// Toggle reading guide
function toggleReadingGuide() {
	const content = document.getElementById('reading-guide-content');
	const toggle = document.getElementById('guide-toggle');
	
	if (content.style.display === 'none' || content.style.display === '') {
		content.style.display = 'block';
		toggle.style.transform = 'rotate(180deg)';
		toggle.textContent = '▲';
	} else {
		content.style.display = 'none';
		toggle.style.transform = 'rotate(0deg)';
		toggle.textContent = '▼';
	}
}

function filterPapers(category) {
	const papers = document.querySelectorAll('.paper-card');
	const buttons = document.querySelectorAll('.filter-btn');
	
	// 更新按钮状态
	buttons.forEach(btn => btn.classList.remove('active'));
	event.target.classList.add('active');
	
	// 过滤论文
	papers.forEach(paper => {
		const tags = paper.querySelectorAll('.methodology-tag');
		const paperCategories = Array.from(tags).map(tag => tag.textContent.toLowerCase());
		
		if (category === 'all' || paperCategories.some(cat => cat.includes(category.toLowerCase()))) {
			paper.style.display = 'block';
		} else {
			paper.style.display = 'none';
		}
	});
}
</script>

<section class="hero is-medium" style="background: linear-gradient(135deg, #B22222 0%, #8B0000 50%, #660000 100%);">
	<div class="hero-body">
		<div class="container has-text-centered">
			<h1 class="title is-1" style="color: white; font-family: 'Times New Roman', 'Times', serif; margin-bottom: 20px;">
				Top-10 AI Deception Papers
			</h1>
			<h2 class="subtitle is-4" style="color: #f0f0f0; font-family: 'Times New Roman', 'Times', serif;">
				Most Influential Research in AI Deception Field
			</h2>
			<h3 class="subtitle is-5" style="color: #ffd700; font-family: 'Times New Roman', 'Times', serif; margin-top: 15px; font-weight: bold;">
				📅 Monthly Update - July 2025
			</h3>
		</div>
	</div>
</section>

<section class="section">
	<div class="container is-max-desktop">
		
		<!-- Reading Recommendations Card -->
		<div class="section-card reading-guide" style="background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border: 2px solid #dee2e6; margin: 30px 0; cursor: pointer;" onclick="toggleReadingGuide()">
			<div style="display: flex; align-items: center; justify-content: space-between;">
				<h2 style="color: #2c3e50; margin: 0; font-family: 'Times New Roman', 'Times', serif; font-size: 1.5em;">📚 Reading Recommendations</h2>
				<span id="guide-toggle" style="font-size: 1.5em; color: #6c757d; transition: transform 0.3s ease;">▼</span>
			</div>
			<p style="margin: 10px 0 0 0; color: #495057;">Click to view our curated reading guide for July 2025's latest AI deception research</p>
			
			<div id="reading-guide-content" style="display: none; margin-top: 20px; border-top: 1px solid #dee2e6; padding-top: 20px;">
				<div style="background: white; border-radius: 8px; padding: 20px; margin-bottom: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
					<h3 style="color: #B22222; margin-bottom: 15px; font-family: 'Times New Roman', 'Times', serif;">🎯 Recommended Reading Path</h3>
					<div style="display: grid; gap: 15px;">
						<div style="border-left: 4px solid #B22222; padding-left: 15px;">
							<strong style="color: #2c3e50;">Foundation (Papers #1-2)</strong>
							<p style="margin: 5px 0; color: #495057; font-size: 0.95em;">Start with <em>"Manipulation Attacks"</em> and <em>"Strategic Phrasing"</em> to understand the current threat landscape and subtle deception techniques.</p>
						</div>
						<div style="border-left: 4px solid #DC143C; padding-left: 15px;">
							<strong style="color: #2c3e50;">Detection Methods (Papers #3-4, #6)</strong>
							<p style="margin: 5px 0; color: #495057; font-size: 0.95em;">Learn cutting-edge detection techniques: <em>activation patching</em>, <em>deception probes</em>, and <em>representation analysis</em>.</p>
						</div>
						<div style="border-left: 4px solid #FF6B6B; padding-left: 15px;">
							<strong style="color: #2c3e50;">Evaluation & Measurement (Paper #5)</strong>
							<p style="margin: 5px 0; color: #495057; font-size: 0.95em;">Understand how to measure AI deception through the innovative <em>"Bullshit Index"</em> framework.</p>
						</div>
						<div style="border-left: 4px solid #4ECDC4; padding-left: 15px;">
							<strong style="color: #2c3e50;">Emerging Threats (Paper #7)</strong>
							<p style="margin: 5px 0; color: #495057; font-size: 0.95em;">Explore steganographic capabilities in frontier models and hidden communication channels.</p>
						</div>
						<div style="border-left: 4px solid #45B7D1; padding-left: 15px;">
							<strong style="color: #2c3e50;">Mitigation Strategies (Papers #8-9)</strong>
							<p style="margin: 5px 0; color: #495057; font-size: 0.95em;">Study defense approaches: <em>CONSENSAGENT</em> for sycophancy mitigation and <em>ICLShield</em> for backdoor defense.</p>
						</div>
						<div style="border-left: 4px solid #96CEB4; padding-left: 15px;">
							<strong style="color: #2c3e50;">Advanced Applications (Paper #10)</strong>
							<p style="margin: 5px 0; color: #495057; font-size: 0.95em;">Examine deception in multi-agent economic scenarios and collusive behaviors.</p>
						</div>
					</div>
				</div>
				
				<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-bottom: 20px;">
					<div style="background: white; border-radius: 8px; padding: 15px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
						<h4 style="color: #B22222; margin-bottom: 10px;">🔍 Research Categories</h4>
						<ul style="margin: 0; padding-left: 20px;">
							<li><strong>Detection & Analysis:</strong> Papers #3, #4, #6</li>
							<li><strong>Mitigation & Defense:</strong> Papers #8, #9</li>
							<li><strong>Empirical Studies:</strong> Papers #2, #5, #7, #10</li>
							<li><strong>Theoretical Frameworks:</strong> Paper #1</li>
						</ul>
					</div>
					<div style="background: white; border-radius: 8px; padding: 15px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
						<h4 style="color: #B22222; margin-bottom: 10px;">💡 Study Tips</h4>
						<ul style="margin: 0; padding-left: 20px;">
							<li>Start with abstracts to gauge relevance</li>
							<li>Focus on methodology sections for techniques</li>
							<li>Pay attention to evaluation metrics</li>
							<li>Note limitations and future work</li>
						</ul>
					</div>
				</div>
				
				<div style="background: linear-gradient(45deg, #f8f9fa, #e9ecef); border-radius: 8px; padding: 15px; text-align: center;">
					<p style="margin: 0; color: #495057; font-style: italic;">
						🌟 All papers are from <strong>July 2025</strong>, ensuring you're accessing the most current developments in AI deception research.
						<br>Complement your reading with our <a href="tutorials.html" style="color: #B22222;">tutorials</a> and <a href="overview.html" style="color: #B22222;">overview</a> sections.
					</p>
				</div>
			</div>
		</div>
		
		<!-- 筛选按钮 -->
		<div class="filter-buttons">
			<button class="filter-btn active" onclick="filterPapers('all')">All Papers</button>
			<button class="filter-btn" onclick="filterPapers('empirical')">Empirical Studies</button>
			<button class="filter-btn" onclick="filterPapers('theoretical')">Theoretical</button>
			<button class="filter-btn" onclick="filterPapers('detection')">Detection</button>
			<button class="filter-btn" onclick="filterPapers('mitigation')">Mitigation</button>
		</div>

		<!-- 论文列表 -->
		<div class="paper-card">
			<div class="paper-rank">1</div>
			<div class="impact-score">🔥 Latest July 2025</div>
			<div style="text-align: center; margin: 20px 40px;">
				<img src="./top10papers/july/images/Manipulation Attacks by Misaligned AI.png" alt="Manipulation Attacks by Misaligned AI" style="max-width: 100%; height: 200px; object-fit: cover; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
			</div>
			<div class="paper-title">Manipulation Attacks by Misaligned AI: Risk Analysis and Safety Case Framework</div>
			<div class="paper-authors">Rishane Dassanayake et al.</div>
			<div class="paper-venue">July 18, 2025</div>
			<div class="paper-abstract">
				Examines the risk of manipulation attacks from LLM-based agents, including cases where AI systems strategically deceive humans to remove safeguards. Proposes a structured safety framework: proving inability, enforcing control, and ensuring trustworthiness to defend against strategic AI-driven deception.
			</div>
			<div style="margin-left: 40px; margin-bottom: 15px;">
				<span class="methodology-tag">Theoretical</span>
				<span class="methodology-tag">Safety Framework</span>
				<span class="methodology-tag">Risk Analysis</span>
			</div>
			<div class="paper-links">
				<a href="https://arxiv.org/abs/2507.12872" class="paper-link" target="_blank">📄 Paper</a>
			</div>
		</div>

		<div class="paper-card">
			<div class="paper-rank">2</div>
			<div class="impact-score">🔥 Latest July 2025</div>
			<div style="text-align: center; margin: 20px 40px;">
				<img src="./top10papers/july/images/Language Models can Subtly Deceive Without Lying.png" alt="Language Models can Subtly Deceive Without Lying" style="max-width: 100%; height: 200px; object-fit: cover; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
			</div>
			<div class="paper-title">Language Models Can Subtly Deceive Without Lying: A Case Study on Strategic Phrasing in Legislation</div>
			<div class="paper-authors">Samyak Dogra et al.</div>
			<div class="paper-venue">ACL 2025</div>
			<div class="paper-abstract">
				Investigates how LLMs use subtle, strategic phrasing to influence legislative decision-making without producing outright falsehoods. Finds that deception success rates increase by up to 40% when phrasing strategies are optimized.
			</div>
			<div style="margin-left: 40px; margin-bottom: 15px;">
				<span class="methodology-tag">Empirical</span>
				<span class="methodology-tag">Strategic Deception</span>
				<span class="methodology-tag">Linguistic Manipulation</span>
			</div>
			<div class="paper-links">
				<a href="https://aclanthology.org/2025.acl-long.1600/" class="paper-link" target="_blank">📄 Paper</a>
			</div>
		</div>

		<div class="paper-card">
			<div class="paper-rank">3</div>
			<div class="impact-score">🔥 Latest July 2025</div>
			<div style="text-align: center; margin: 20px 40px;">
				<img src="./top10papers/july/images/Adversarial Activation Patching.png" alt="Adversarial Activation Patching" style="max-width: 100%; height: 200px; object-fit: cover; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
			</div>
			<div class="paper-title">Adversarial Activation Patching: A Framework for Detecting and Mitigating Emergent Deception in Safety-Aligned Transformers</div>
			<div class="paper-authors">Santhosh Kumar Ravindran</div>
			<div class="paper-venue">July 14, 2025</div>
			<div class="paper-abstract">
				Uses activation patching to identify and induce deceptive behavior in RLHF-trained models. Pinpoints sparse, deception-related neurons and layers, enabling targeted mitigation strategies by detecting anomalous activations or fine-tuning on patched datasets.
			</div>
			<div style="margin-left: 40px; margin-bottom: 15px;">
				<span class="methodology-tag">Detection</span>
				<span class="methodology-tag">Mitigation</span>
				<span class="methodology-tag">Activation Patching</span>
			</div>
			<div class="paper-links">
				<a href="https://arxiv.org/abs/2507.09406" class="paper-link" target="_blank">📄 Paper</a>
			</div>
		</div>

		<div class="paper-card">
			<div class="paper-rank">4</div>
			<div class="impact-score">🔥 Latest July 2025</div>
			<div style="text-align: center; margin: 20px 40px;">
				<img src="./top10papers/july/images/Benchmarking Deception Probes.png" alt="Benchmarking Deception Probes" style="max-width: 100%; height: 200px; object-fit: cover; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
			</div>
			<div class="paper-title">Benchmarking Deception Probes via Black-to-White Performance Boosts</div>
			<div class="paper-authors">Avi Parrack, Carlo L. Attubato, Stefan Heimersheim</div>
			<div class="paper-venue">July 12, 2025</div>
			<div class="paper-abstract">
				Evaluates "deception probes" trained on LLM hidden activations to distinguish lies from truthful statements. Finds white-box probes outperform black-box detectors but only modestly, suggesting that current detection approaches remain fragile against adversarially deceptive models.
			</div>
			<div style="margin-left: 40px; margin-bottom: 15px;">
				<span class="methodology-tag">Detection</span>
				<span class="methodology-tag">Benchmarking</span>
				<span class="methodology-tag">Empirical</span>
			</div>
			<div class="paper-links">
				<a href="https://arxiv.org/abs/2507.12691" class="paper-link" target="_blank">📄 Paper</a>
			</div>
		</div>

		<div class="paper-card">
			<div class="paper-rank">5</div>
			<div class="impact-score">🔥 Latest July 2025</div>
			<div style="text-align: center; margin: 20px 40px;">
				<img src="./top10papers/july/images/Machine Bullshit.png" alt="Machine Bullshit" style="max-width: 100%; height: 200px; object-fit: cover; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
			</div>
			<div class="paper-title">Machine Bullshit: Characterizing the Emergent Disregard for Truth in Large Language Models</div>
			<div class="paper-authors">Liang et al.</div>
			<div class="paper-venue">July 10, 2025</div>
			<div class="paper-abstract">
				Introduces a Bullshit Index, a metric to measure LLMs' indifference to truth. Identifies four forms: empty rhetoric, paltering, weasel words, and unverified claims. Finds RLHF and chain-of-thought prompting often exacerbate these behaviors.
			</div>
			<div style="margin-left: 40px; margin-bottom: 15px;">
				<span class="methodology-tag">Empirical</span>
				<span class="methodology-tag">Evaluation Metrics</span>
				<span class="methodology-tag">Truth Indifference</span>
			</div>
			<div class="paper-links">
				<a href="https://arxiv.org/abs/2507.07484" class="paper-link" target="_blank">📄 Paper</a>
			</div>
		</div>

		<div class="paper-card">
			<div class="paper-rank">6</div>
			<div class="impact-score">🔥 Latest July 2025</div>
			<div style="text-align: center; margin: 20px 40px;">
				<img src="./top10papers/july/images/When Truthful Representations Flip Under Deceptive Instructions.png" alt="When Truthful Representations Flip Under Deceptive Instructions" style="max-width: 100%; height: 200px; object-fit: cover; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
			</div>
			<div class="paper-title">When Truthful Representations Flip Under Deceptive Instructions?</div>
			<div class="paper-authors">Xianxuan Long et al.</div>
			<div class="paper-venue">July 10, 2025</div>
			<div class="paper-abstract">
				Analyzes how hidden representations in transformer models change under deceptive instructions. Finds distinct latent patterns in middle layers when prompted to lie, suggesting potential for early detection of deceptive outputs using linear probes on activations.
			</div>
			<div style="margin-left: 40px; margin-bottom: 15px;">
				<span class="methodology-tag">Detection</span>
				<span class="methodology-tag">Representation Analysis</span>
				<span class="methodology-tag">Interpretability</span>
			</div>
			<div class="paper-links">
				<a href="https://arxiv.org/abs/2507.22149" class="paper-link" target="_blank">📄 Paper</a>
			</div>
		</div>

		<div class="paper-card">
			<div class="paper-rank">7</div>
			<div class="impact-score">🔥 Latest July 2025</div>
			<div style="text-align: center; margin: 20px 40px;">
				<img src="./top10papers/july/images/Early Signs of Steganographic Capabilities in Frontier LLMs.png" alt="Early Signs of Steganographic Capabilities in Frontier LLMs" style="max-width: 100%; height: 200px; object-fit: cover; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
			</div>
			<div class="paper-title">Early Signs of Steganographic Capabilities in Frontier LLMs</div>
			<div class="paper-authors">Artur Zolkowski et al.</div>
			<div class="paper-venue">July 3, 2025</div>
			<div class="paper-abstract">
				Evaluates steganography capabilities in frontier LLMs, focusing on how models could evade monitoring through encoding hidden information within seemingly benign generations. The study examines both passing encoded messages and performing encoded reasoning.
			</div>
			<div style="margin-left: 40px; margin-bottom: 15px;">
				<span class="methodology-tag">Empirical</span>
				<span class="methodology-tag">Steganography</span>
				<span class="methodology-tag">Hidden Communication</span>
			</div>
			<div class="paper-links">
				<a href="https://arxiv.org/abs/2507.02737" class="paper-link" target="_blank">📄 Paper</a>
			</div>
		</div>

		<div class="paper-card">
			<div class="paper-rank">8</div>
			<div class="impact-score">🔥 Latest July 2025</div>
			<div style="text-align: center; margin: 20px 40px;">
				<img src="./top10papers/july/images/ConsentAgent.png" alt="CONSENSAGENT" style="max-width: 100%; height: 200px; object-fit: cover; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
			</div>
			<div class="paper-title">CONSENSAGENT: Efficient and Effective Consensus in Multi-Agent LLM Systems through Sycophancy Mitigation</div>
			<div class="paper-authors">Priya Pitre, Naren Ramakrishnan, Xuan Wang</div>
			<div class="paper-venue">ACL 2025 Findings</div>
			<div class="paper-abstract">
				Proposes CONSENSAGENT, a system for mitigating sycophancy in multi-agent LLM setups. Encourages controlled dissent among agents to avoid echo-chamber agreement, improving consensus accuracy on six reasoning benchmarks while lowering computational costs.
			</div>
			<div style="margin-left: 40px; margin-bottom: 15px;">
				<span class="methodology-tag">Mitigation</span>
				<span class="methodology-tag">Multi-Agent Systems</span>
				<span class="methodology-tag">Sycophancy</span>
			</div>
			<div class="paper-links">
				<a href="https://aclanthology.org/2025.findings-acl.1123/" class="paper-link" target="_blank">📄 Paper</a>
			</div>
		</div>

		<div class="paper-card">
			<div class="paper-rank">9</div>
			<div class="impact-score">🔥 Latest July 2025</div>
			<div style="text-align: center; margin: 20px 40px;">
				<img src="./top10papers/july/images/ICLShield- Exploring and Mitigating In-Context Learning Backdoor Attacks.png" alt="ICLShield" style="max-width: 100%; height: 200px; object-fit: cover; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
			</div>
			<div class="paper-title">ICLShield: Exploring and Mitigating In-Context Learning Backdoor Attacks</div>
			<div class="paper-authors">Zhiyao Ren et al.</div>
			<div class="paper-venue">July 2, 2025</div>
			<div class="paper-abstract">
				Addresses vulnerabilities in in-context learning where adversaries can manipulate LLM behaviors by poisoning demonstrations. Proposes the dual-learning hypothesis and introduces ICLShield defense mechanism.
			</div>
			<div style="margin-left: 40px; margin-bottom: 15px;">
				<span class="methodology-tag">Mitigation</span>
				<span class="methodology-tag">Security</span>
				<span class="methodology-tag">Backdoor Defense</span>
			</div>
			<div class="paper-links">
				<a href="https://arxiv.org/abs/2507.01321" class="paper-link" target="_blank">📄 Paper</a>
			</div>
		</div>

		<div class="paper-card">
			<div class="paper-rank">10</div>
			<div class="impact-score">🔥 Latest July 2025</div>
			<div style="text-align: center; margin: 20px 40px;">
				<img src="./top10papers/july/images/Evaluating LLM Agent Collusion in Double Auctions.png" alt="Evaluating LLM Agent Collusion in Double Auctions" style="max-width: 100%; height: 200px; object-fit: cover; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
			</div>
			<div class="paper-title">Evaluating LLM Agent Collusion in Double Auctions</div>
			<div class="paper-authors">Kushal Agrawal et al.</div>
			<div class="paper-venue">July 2, 2025</div>
			<div class="paper-abstract">
				Examines scenarios where LLM agents can choose to collude (secretive cooperation that harms another party) in simulated continuous double auction markets, analyzing how communication, model choice, and environmental pressures affect collusive tendencies.
			</div>
			<div style="margin-left: 40px; margin-bottom: 15px;">
				<span class="methodology-tag">Empirical</span>
				<span class="methodology-tag">Agent Behavior</span>
				<span class="methodology-tag">Economic Simulation</span>
			</div>
			<div class="paper-links">
				<a href="https://arxiv.org/abs/2507.01413" class="paper-link" target="_blank">📄 Paper</a>
			</div>
		</div>



	</div>
</section>

<footer class="footer">
	<div class="content has-text-centered">
		<p style="color: #666; font-family: 'Times New Roman', 'Times', serif;">
			© 2025 PKU-Alignment Team. This website is adapted from <a href="https://nerfies.github.io/">Nerfies</a>, 
			licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
		</p>
	</div>
</footer>

</body>
</html>
