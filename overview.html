<!DOCTYPE html>
<html class="fontawesome-i2svg-active fontawesome-i2svg-complete">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<meta name="description" content="AI Deception Survey Overview">
	<meta name="keywords" content="AI Deception, Survey, AI Safety, AI Alignment, Overview">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Overview - AI Deception Survey</title>
	<link rel="icon" href="./assets/logo_transp.png" type="image/png">
	<!-- ÂºïÂÖ•cssÊñá‰ª∂ -->
	<link href="./assets/css" rel="stylesheet">
	<link rel="stylesheet" href="./assets/bulma.min.css">
	<link rel="stylesheet" href="./assets/bulma-carousel.min.css">
	<link rel="stylesheet" href="./assets/font-face.css">
	<link rel="stylesheet" href="./assets/bulma-slider.min.css">
	<link rel="stylesheet" href="./assets/fontawesome.all.min.css">
	<link rel="stylesheet" href="./assets/academicons.min.css">
	<link rel="stylesheet" href="./assets/index.css">
	<link rel="stylesheet" href="./assets/leaderboard.css">
	<link rel="stylesheet" href="./assets/navbar.css">
	<style>
		p, ul {
		text-align: justify;
		margin-left: auto;
		margin-right: auto;
		width: 75%;
		list-style:disc;
		margin-bottom: 10px;
		}
		
		/* Ë¶ÜÁõñÂÖ®Â±ÄpÊ†áÁ≠æÊ†∑ÂºèÔºåÁ°Æ‰øùÂ≠¶ÊúØÂÜÖÂÆπÂ∑¶ÂØπÈΩê */
		.academic-content p,
		.formal-definition-box p {
			text-align: left !important;
			width: auto !important;
			margin-left: 0 !important;
			margin-right: 0 !important;
		}
		li {
		margin-bottom: 10px;
		}
		
		.section-card {
		background-color: #f8f9fa;
		border: 1px solid #e1e5e9;
		border-radius: 12px;
		padding: 25px;
		margin: 25px 0;
		box-shadow: 0 4px 8px rgba(0,0,0,0.1);
		transition: transform 0.3s ease, box-shadow 0.3s ease;
		}
		
		.section-card:hover {
		transform: translateY(-5px);
		box-shadow: 0 8px 16px rgba(0,0,0,0.15);
		}
		
		.section-card h3 {
		color: #2c3e50;
		margin-bottom: 15px;
		}
		
		.section-card h2 {
		color: #2c3e50;
		margin-bottom: 20px;
		font-size: 2.5em;
		font-weight: bold;
		text-align: center;
		}
		
		.timeline-item {
		background: white;
		border-left: 4px solid #DC143C;
		padding: 20px;
		margin: 20px 0;
		border-radius: 8px;
		box-shadow: 0 2px 4px rgba(0,0,0,0.1);
		}
		
		.timeline-year {
		color: #DC143C;
		font-weight: bold;
		font-size: 1.2em;
		}
		
		.stats-grid {
		display: grid;
		grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
		gap: 20px;
		margin: 30px 0;
		}
		
		.stats-card {
		background: linear-gradient(135deg, #B22222, #DC143C);
		color: white;
		padding: 25px;
		border-radius: 12px;
		text-align: center;
		box-shadow: 0 4px 8px rgba(0,0,0,0.2);
		}
		
		.stats-number {
		font-size: 3em;
		font-weight: bold;
		margin-bottom: 10px;
		}
		
				.stats-label {
			font-size: 1.1em;
			opacity: 0.9;
		}
		
		/* Academic style overrides */
		.academic-section {
			padding: 80px 0;
		}
		
		.academic-title {
			font-family: 'Times New Roman', 'Times', serif;
			font-size: 2.8em;
			font-weight: 700;
			color: #2c3e50;
			text-align: center;
			margin-bottom: 50px;
			line-height: 1.2;
		}
		
		.academic-content {
			max-width: 1000px;
			margin: 0 auto;
			padding: 0 20px;
		}
		
		.lead-paragraph {
			font-size: 1.3em;
			line-height: 1.6;
			color: #2c3e50;
			text-align: center;
			margin-bottom: 40px;
			font-family: 'Times New Roman', 'Times', serif;
		}
		
		.formal-definition-box {
			background: #f8f9fa;
			border-left: 5px solid #B22222;
			padding: 40px;
			border-radius: 8px;
			margin: 40px auto;
			box-shadow: 0 2px 8px rgba(0,0,0,0.1);
			max-width: 1000px;
			width: 100%;
			box-sizing: border-box;
		}
		
		.definition-title {
			font-family: 'Times New Roman', 'Times', serif;
			font-size: 1.4em;
			font-weight: 700;
			color: #B22222;
			margin-bottom: 20px;
		}
		
		.definition-content {
			font-size: 1.1em;
			line-height: 1.7;
			color: #2c3e50;
			margin-bottom: 15px;
			text-align: left;
		}
		
		.definition-conditions {
			margin: 20px 0;
			padding-left: 30px;
		}
		
		.definition-conditions li {
			font-size: 1.1em;
			line-height: 1.6;
			margin-bottom: 8px;
			color: #2c3e50;
		}
		
		.definition-conclusion,
		.definition-extension {
			font-size: 1.1em;
			line-height: 1.7;
			color: #2c3e50;
			margin: 15px 0;
			text-align: left;
		}
		
		.figure-container {
			text-align: center;
			margin: 40px 0;
		}
		
		.academic-figure {
			max-width: 100%;
			height: auto;
			border-radius: 8px;
			box-shadow: 0 4px 12px rgba(0,0,0,0.15);
		}
		
		.academic-figure-small {
			max-width: 100%;
			height: auto;
			border-radius: 8px;
			box-shadow: 0 4px 12px rgba(0,0,0,0.15);
		}
		
		.figure-description {
			font-size: 1.1em;
			line-height: 1.6;
			color: #2c3e50;
			margin-top: 25px;
			text-align: left;
			font-style: italic;
		}
		
		.two-column-layout {
			display: grid;
			grid-template-columns: 1fr 1fr;
			gap: 40px;
			align-items: center;
		}
		
		.text-column {
			padding-right: 20px;
		}
		
		.image-column {
			text-align: center;
		}
		
		.academic-text {
			font-size: 1.1em;
			line-height: 1.7;
			color: #2c3e50;
			text-align: left;
		}
		
		.risk-levels {
			margin-top: 30px;
		}
		
		.risk-description,
		.risk-conclusion {
			font-size: 1.1em;
			line-height: 1.7;
			color: #2c3e50;
			text-align: left;
			margin-bottom: 20px;
		}
		
		.subsection-title {
			font-family: 'Times New Roman', 'Times', serif;
			font-size: 2.2em;
			font-weight: 600;
			color: #B22222;
			margin-bottom: 40px;
			text-align: center;
		}
		
		.chapter-title {
			font-family: 'Times New Roman', 'Times', serif;
			font-size: 3.2em;
			font-weight: 800;
			color: #8B0000;
			text-align: center;
			margin-bottom: 60px;
			text-transform: uppercase;
			letter-spacing: 2px;
			text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
		}
		
					/* Áªü‰∏ÄÂä†Á≤óÊñáÂ≠ó‰∏∫ÊöóÁ∫¢Ëâ≤ */
			strong, b {
				color: #8B0000;
				font-weight: bold;
			}
			
			/* Á°Æ‰øùÂÆö‰πâÊ°ÜÂÜÖÁöÑÊñáÂ≠óÂØπÈΩê */
			.formal-definition-box *,
			.formal-definition-box p,
			.formal-definition-box ol,
			.formal-definition-box li {
				text-align: left !important;
				width: auto !important;
				margin-left: 0 !important;
				margin-right: 0 !important;
			}
			
			.definition-conditions {
				text-align: left !important;
				width: auto !important;
				margin-left: 30px !important;
				margin-right: 0 !important;
			}
			
			@media (max-width: 768px) {
				.two-column-layout {
					grid-template-columns: 1fr;
					gap: 30px;
				}
				
				.academic-title {
					font-size: 2.2em;
				}
				
				.chapter-title {
					font-size: 2.5em;
				}
				
				.subsection-title {
					font-size: 1.8em;
				}
				
				.formal-definition-box {
					padding: 25px;
					margin: 30px 15px;
				}
			}
	</style>
</head>

<nav class="navbar is-light" role="navigation" aria-label="main navigation" style="padding: 0; box-shadow: 0 4px 12px rgba(0,0,0,0.15); background: linear-gradient(to bottom, #ffffff 0%, #f8f9fa 100%); border-bottom: 1px solid #e9ecef;">
	<div class="container" style="max-width: 1200px; margin: 0 auto; padding: 0 40px;">
		<div class="navbar-brand">
			<a class="navbar-item" href="index.html" style="font-weight: bold; font-size: 1.3em; color: #000000; font-family: 'Times New Roman', 'Times', serif; margin-left: 20px;">
				AI Deception
			</a>
			<a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false" data-target="navbarBasicExample">
				<span aria-hidden="true"></span>
				<span aria-hidden="true"></span>
				<span aria-hidden="true"></span>
			</a>
		</div>

		<div id="navbarBasicExample" class="navbar-menu">
			<div class="navbar-start" style="margin-left: 60px;">
				<a class="navbar-item" href="overview.html" style="font-weight: 500; color: #000000; font-family: 'Times New Roman', 'Times', serif; transition: all 0.3s ease; position: relative; background-color: rgba(220, 20, 60, 0.1);" onmouseover="this.style.color='#DC143C'; this.style.transform='translateY(-2px)'" onmouseout="this.style.color='#000000'; this.style.transform='translateY(0)'">
					Overview
				</a>
				
				<a class="navbar-item" href="top10papers.html" style="font-weight: 500; color: #000000; font-family: 'Times New Roman', 'Times', serif; transition: all 0.3s ease; position: relative;" onmouseover="this.style.color='#DC143C'; this.style.transform='translateY(-2px)'" onmouseout="this.style.color='#000000'; this.style.transform='translateY(0)'">
					Top-10 Papers
				</a>
				
				<a class="navbar-item" href="tutorials.html" style="font-weight: 500; color: #000000; font-family: 'Times New Roman', 'Times', serif; transition: all 0.3s ease; position: relative;" onmouseover="this.style.color='#DC143C'; this.style.transform='translateY(-2px)'" onmouseout="this.style.color='#000000'; this.style.transform='translateY(0)'">
					Tutorials
				</a>
				
				<div class="navbar-item has-dropdown is-hoverable">
					<a class="navbar-link" style="font-weight: 500; color: #000000; font-family: 'Times New Roman', 'Times', serif; transition: all 0.3s ease;" onmouseover="this.style.color='#DC143C'" onmouseout="this.style.color='#000000'">
						More Research
					</a>
					<div class="navbar-dropdown" style="box-shadow: 0 8px 16px rgba(0,0,0,0.1); border: 1px solid #e9ecef;">
						<a class="navbar-item" href="https://pku-lm-resist-alignment.github.io/" target="_blank" style="font-family: 'Times New Roman', 'Times', serif;">
							<b>Resist (ACL2025 <span style="color: #DC143C; font-weight: bold;">Best Paper</span>)</b>
						</a>
						<a class="navbar-item" href="https://github.com/PKU-Alignment/safe-rlhf" target="_blank" style="font-family: 'Times New Roman', 'Times', serif;">
							<b>SafeRLHF (ICLR 2024 Spotlight)</b>
						</a>
						<a class="navbar-item" href="https://huggingface.co/datasets/PKU-Alignment/PKU-SafeRLHF" target="_blank" style="font-family: 'Times New Roman', 'Times', serif;">
							<b>PKU-SafeRLHF (ACL2025 Main)</b>
						</a>
						<a class="navbar-item" href="https://github.com/PKU-Alignment/aligner" target="_blank" style="font-family: 'Times New Roman', 'Times', serif;">
							<b>Aligner (NeurIPS 2024 Oral)</b>
						</a>
						<a class="navbar-item" href="https://github.com/PKU-Alignment/safe-sora" target="_blank" style="font-family: 'Times New Roman', 'Times', serif;">
							<b>SafeSora (NeurIPS 2024 DB Track)</b>
						</a>
						<a class="navbar-item" href="https://github.com/PKU-Alignment/beavertails" target="_blank" style="font-family: 'Times New Roman', 'Times', serif;">
							<b>BeaverTails (NeurIPS 2023 DB Track)</b>
						</a>
						<a class="navbar-item" href="https://align-anything.readthedocs.io/en/latest/index.html" target="_blank" style="font-family: 'Times New Roman', 'Times', serif;">
							<b>Align-Anythingüî•üî•üî•</b>
						</a>
						<a class="navbar-item" href="https://alignmentsurvey.com" target="_blank" style="font-family: 'Times New Roman', 'Times', serif;">
							<b>AI Alignment: A Comprehensive Survey</b>
						</a>
					</div>
				</div>
			</div>

			<div class="navbar-end">
				<div class="navbar-item">
					<div class="field has-addons">
						<div class="control">
							<input class="input" type="text" id="searchInput" placeholder="Search papers, topics..." style="width: 280px; font-family: 'Times New Roman', 'Times', serif; border: 2px solid #e9ecef; border-radius: 8px 0 0 8px; box-shadow: inset 0 2px 4px rgba(0,0,0,0.1);">
						</div>
						<div class="control">
							<button class="button" onclick="performSearch()" style="background: linear-gradient(45deg, #B22222, #DC143C); color: white; border: none; border-radius: 0 8px 8px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1); transition: all 0.3s ease;" onmouseover="this.style.transform='scale(1.05)'" onmouseout="this.style.transform='scale(1)'">
								<span class="icon">
									<svg width="16" height="16" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
										<path d="M21 21L16.514 16.506L21 21ZM19 10.5C19 15.194 15.194 19 10.5 19C5.806 19 2 15.194 2 10.5C2 5.806 5.806 2 10.5 2C15.194 2 19 5.806 19 10.5Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
									</svg>
								</span>
							</button>
						</div>
					</div>
				</div>
			</div>
		</div>
	</div>
</nav>

<script>
function performSearch() {
	const searchTerm = document.getElementById('searchInput').value.toLowerCase();
	if (searchTerm.trim() === '') {
		alert('ËØ∑ËæìÂÖ•ÊêúÁ¥¢ÂÜÖÂÆπ');
		return;
	}
	
	// ÊêúÁ¥¢È°µÈù¢ÂÜÖÂÆπ
	const sections = document.querySelectorAll('.section-card, .content p, h1, h2, h3, .timeline-item');
	let found = false;
	
	sections.forEach(section => {
		const text = section.textContent.toLowerCase();
		if (text.includes(searchTerm)) {
			section.scrollIntoView({ behavior: 'smooth', block: 'center' });
			section.style.backgroundColor = '#ffeb3b';
			setTimeout(() => {
				section.style.backgroundColor = '';
			}, 3000);
			found = true;
			return;
		}
	});
	
	if (!found) {
		alert(`Êú™ÊâæÂà∞Áõ∏ÂÖ≥ÂÜÖÂÆπ: "${searchTerm}"`);
	}
}

// ÂõûËΩ¶ÈîÆÊêúÁ¥¢
document.getElementById('searchInput').addEventListener('keypress', function(e) {
	if (e.key === 'Enter') {
		performSearch();
	}
});

// ÁßªÂä®Á´ØÂØºËà™Ê†èÊ±âÂ†°ËèúÂçïÂäüËÉΩ
document.addEventListener('DOMContentLoaded', function() {
	const navbarBurger = document.querySelector('.navbar-burger');
	const navbarMenu = document.querySelector('.navbar-menu');
	
	if (navbarBurger && navbarMenu) {
		navbarBurger.addEventListener('click', function() {
			// ÂàáÊç¢is-activeÁ±ª
			navbarBurger.classList.toggle('is-active');
			navbarMenu.classList.toggle('is-active');
		});
	}
});
</script>

<section class="hero is-medium" style="background: linear-gradient(135deg, #B22222 0%, #8B0000 50%, #660000 100%);">
	<div class="hero-body">
		<div class="container has-text-centered">
			<h1 class="title is-1" style="color: white; font-family: 'Times New Roman', 'Times', serif; margin-bottom: 20px;">
				AI Deception Survey Overview
			</h1>
			<h2 class="subtitle is-4" style="color: #f0f0f0; font-family: 'Times New Roman', 'Times', serif;">
				Comprehensive Research Landscape and Key Findings
			</h2>
		</div>
	</div>
</section>

<!-- AI Deception Definition Section -->
<section class="academic-section" style="background-color: #ffffff; padding: 80px 0;">
	<div class="container is-max-desktop">
		<h1 class="academic-title">AI Deception Definition</h1>
		<div class="academic-content">
			<p class="lead-paragraph">
				<strong>AI deception</strong> can be broadly defined as <em>behavior by AI systems that induces false beliefs in humans or other AI systems, thereby securing outcomes that are advantageous to the AI itself</em>.
			</p>
			
			<div class="formal-definition-box">
				<h3 class="definition-title">Formal Definition: AI Deception</h3>
				<p class="definition-content">
					At time step <em>t</em> (potentially within a long-horizon task), the signaler emits a signal <em>Y<sub>t</sub></em> to the receiver, prompting the receiver to form a belief <em>X<sub>t</sub></em> about an underlying state and subsequently take an action <em>A<sub>t</sub></em>. If the following three conditions hold:
				</p>
				<ol class="definition-conditions">
					<li><em>A<sub>t</sub></em> benefits the signaler (<em>i.e.</em>, yields a positive utility).</li>
					<li><em>A<sub>t</sub></em> is a rational response given the belief <em>X<sub>t</sub></em>,</li>
					<li>The belief <em>X<sub>t</sub></em> is objectively false,</li>
				</ol>
				<p class="definition-conclusion">
					then <em>Y<sub>t</sub></em> is classified as a <strong>deceptive signal</strong>, and the entire interaction constitutes an instance of <strong>deception</strong>.
				</p>
				<p class="definition-extension">
					In more general dynamic settings, deception can be modeled as a temporal process where the signaler emits a sequence of signals <em>Y<sub>t</sub></em> over time steps <em>t = 1, ..., T</em>, thereby shaping the receiver's belief state <em>b<sub>t</sub></em>. If this belief trajectory systematically diverges from the ground truth <em>X<sub>t</sub></em>, and this divergence consistently benefits the signaler, it constitutes a case of <strong>sustained deception</strong>.
				</p>
			</div>
		</div>
	</div>
</section>

<!-- AI Deception Cycle Section -->
<section class="academic-section" style="background-color: #f8f9fa; padding: 80px 0;">
	<div class="container is-max-desktop">
		<h1 class="academic-title">AI Deception Cycle</h1>
		<div class="academic-content">
			<div class="figure-container">
				<img src="./overview/images/ai_deception_cycle.png" alt="AI Deception Cycle" class="academic-figure">
			</div>
			<p class="figure-description">
				<strong>The AI Deception Cycle.</strong> (1) The framework is structured around a cyclical interaction between the <strong>Deception Genesis</strong> process and the <strong>Deception Mitigation</strong> process. (2) The Deception Genesis identifies the conditions under which deception arises‚Äînamely, <em>incentive foundation</em>, <em>capability precondition</em>, and <em>contextual trigger</em>‚Äîwhile the Deception Mitigation addresses <em>detection</em>, <em>evaluation</em>, and <em>potential solutions</em> anchored in these genesis factors. However, deception mitigation is rarely once-and-for-all; models may continually develop new ways to circumvent oversight, giving rise to increasingly sophisticated deceptive behaviors. This dynamic makes deception a <strong>persistent challenge</strong> throughout the entire system lifecycle.
			</p>
		</div>
	</div>
</section>

<!-- Empirical Studies Section -->
<section class="academic-section" style="background-color: #ffffff; padding: 80px 0;">
	<div class="container is-max-desktop">
		<h1 class="academic-title">Empirical Studies</h1>
		<div class="academic-content">
			<div class="two-column-layout">
				<div class="text-column">
					<p class="academic-text">
						<strong>Taxonomy of AI deception</strong> across three classes: <em>Behavioral-Signaling Deception</em>, <em>Internal Process Deception</em>, and <em>Goal-Environment Deception</em>. AI deceptions are mapped along dimensions of <strong>oversight vigilance</strong> and <strong>detection difficulty</strong>, showing progression from overt behavioral signals to covert environmental manipulation.
					</p>
				</div>
				<div class="image-column">
					<img src="./overview/images/empirical_studies.png" alt="Empirical Studies Taxonomy" class="academic-figure-small">
				</div>
			</div>
		</div>
	</div>
</section>

<!-- Risks of AI Deception Section -->
<section class="academic-section" style="background-color: #f8f9fa; padding: 80px 0;">
	<div class="container is-max-desktop">
		<h1 class="academic-title">Risks of AI Deception</h1>
		<div class="academic-content">
			<div class="figure-container">
				<img src="./overview/images/risks.png" alt="Risks of AI Deception" class="academic-figure">
			</div>
			<p class="academic-text">
				We propose a <strong>five-level risk typology</strong>. The framework organizes deceptive risks along two dimensions: the <em>duration of interaction</em> (from short-term use to long-term engagement) and the <em>scope of impact</em> (from individual users to society-wide).
			</p>
			<div class="risk-levels">
				<p class="risk-description">
					At the first level, <strong>R1: Cognitive Misleading</strong> captures localized effects, where users form false beliefs or misplaced trust based on subtle distortions. <strong>R2: Strategic Manipulation</strong> reflects how, over prolonged interactions, users can be steered toward entrenched misconceptions or behavioral dependencies that are difficult to reverse. <strong>R3: Objective Misgeneralization</strong> highlights failures in specialized or high-stakes domains, where deceptively competent outputs can lead to software errors, economic losses, or fraud. <strong>R4: Institutional Erosion</strong> emphasizes the erosion of trust in science, governance, and epistemic institutions when deceptive practices scale, weakening social coordination and accountability. Finally, <strong>R5: Capability Concealment with Runaway Potential</strong> points to scenarios where hidden capabilities and long-horizon deception undermine human oversight entirely, raising prospects of uncontrollable system behavior.
				</p>
				<p class="risk-conclusion">
					Each level represents a <strong>qualitatively distinct failure mode</strong>, with higher levels introducing risks that are harder to detect and reverse. Crucially, mitigation at lower levels does not guarantee safety at higher levels, as seemingly innocuous deceptive behaviors can accumulate into <strong>systemic threats</strong>.
				</p>
			</div>
		</div>
	</div>
</section>

<!-- Deception Genesis Main Section -->
<section class="academic-section" style="background-color: #ffffff; padding: 80px 0;">
	<div class="container is-max-desktop">
		<h1 class="chapter-title">Deception Genesis: Incentive Foundation √ó Capability √ó Trigger</h1>
		
		<!-- Incentive Foundation Subsection -->
		<div class="academic-content" style="margin-bottom: 80px;">
			<h2 class="subsection-title">Incentive Foundation</h2>
			<div class="figure-container">
				<img src="./overview/images/incentive_foundations.png" alt="Incentive Foundations" class="academic-figure">
			</div>
			<p class="academic-text">
				As the training stage progresses, root causes of emergent deception arise sequentially as the <em>deception ladder</em>. Before training, <strong>data contamination</strong> occurs when preparing training data; <strong>reward misspecification</strong> occurs when designing the training procedure; they collectively form the seed of deceptive strategies. During the training, due to <strong>goal misgeneralization</strong>, deceptive strategies are internalized and stabilized into instrumental goals. Later in deployment, these goals may drive more sophisticated forms of deception that are harder to detect and pose greater risks.
			</p>
		</div>
		
		<!-- Capability Precondition Subsection -->
		<div class="academic-content" style="margin-bottom: 80px;">
			<h2 class="subsection-title">Capability Precondition</h2>
			<div class="figure-container">
				<img src="./overview/images/capability.png" alt="Capability Preconditions" class="academic-figure">
			</div>
			<p class="academic-text">
				<strong>Hierarchical organization</strong> of AI capabilities that correlate with deception, grouped into three categories: <em>Perception</em>, <em>Planning</em>, and <em>Performing</em>. <span style="color: #8B0000; font-weight: bold;">High-level capabilities</span> are emergent abilities enabling sophisticated deception, while <span style="color: #FF8C00; font-weight: bold;">base capabilities</span> provide the foundational competencies that support them. Examples adapted from agentic misalignment research.
			</p>
		</div>
		
		<!-- Contextual Trigger Subsection -->
		<div class="academic-content">
			<h2 class="subsection-title">Contextual Trigger</h2>
			<div class="figure-container">
				<img src="./overview/images/contextual_triggers.png" alt="Contextual Triggers" class="academic-figure">
			</div>
			<p class="academic-text">
				We categorize contextual triggers into three main categories: <em>Supervision Gap</em>, <em>Distributional Shift</em>, and <em>Environmental Pressure</em>. Each category can independently trigger deception or combine with others to amplify deceptive behavior. Let <em>p<sub>a</sub></em>, <em>p<sub>b</sub></em>, and <em>p<sub>c</sub></em> denote the probabilities of each category triggering deception. The illustrative example is inspired by the "fabricated actions" issue, where a model at test time encounters all three triggers simultaneously. These triggers <strong>amplify the probability</strong> of model deception, leading the model to fabricate actions it claims to have taken to fulfill user requests.
			</p>
		</div>
	</div>
</section>

<!-- Deception Mitigation Section -->
<section class="academic-section" style="background-color: #f8f9fa; padding: 80px 0;">
	<div class="container is-max-desktop">
		<h1 class="academic-title">Deception Mitigation: Detection, Evaluation and Potential Solutions</h1>
		<div class="academic-content">
			<div class="figure-container">
				<img src="./overview/images/deception_mitigation.png" alt="Deception Mitigation" class="academic-figure">
			</div>
			<p class="academic-text">
				<strong>Overview of AI deception-related evaluations.</strong> We organize existing studies from two perspectives: evaluation in <span style="color: #FF8C00; font-weight: bold;">static settings</span> and evaluation in <span style="color: #008B8B; font-weight: bold;">interactive environments</span>, and we annotate each work with its release date, data size, institution, data type, and description.
			</p>
			<div class="figure-container" style="margin-top: 40px;">
				<img src="./overview/images/table_benchmarks.png" alt="Benchmarks Table" class="academic-figure">
			</div>
		</div>
	</div>
</section>

<footer class="footer">
	<div class="content has-text-centered">
		<p style="color: #666; font-family: 'Times New Roman', 'Times', serif;">
			¬© 2025 PKU-Alignment Team. This website is adapted from <a href="https://nerfies.github.io/">Nerfies</a>, 
			licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
		</p>
	</div>
</footer>

</body>
</html>
